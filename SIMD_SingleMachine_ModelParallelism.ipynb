{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIMD_SingleMachine_ModelParallelism.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtPOkzfviL8ZwIY2mV7rP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhilash1910/Accelerated_Deep_Learning/blob/master/SIMD_SingleMachine_ModelParallelism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpW3hTbHLEkg",
        "outputId": "dcbc978a-9efe-4889-c25e-2015eddd041b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PyTorch built with:', '  - GCC 7.3', '  - C++ Version: 201402', '  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications', '  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)', '  - OpenMP 201511 (a.k.a. OpenMP 4.5)', '  - LAPACK is enabled (usually provided by MKL)', '  - NNPACK is enabled', '  - CPU capability usage: AVX2', '  - CUDA Runtime 11.3', '  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86', '  - CuDNN 8.2', '  - Magma 2.5.2', '  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, ', '']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__config__.show().split(\"\\n\"), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "R7652g0bnvux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e317c990-3ab1-4f91-d3c1-91e42b6170bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CfV_g8z4eSf",
        "outputId": "83dfc821-81a7-489c-8bf5-282f6c644691"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 17 18:17:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z42zxjC4ghQ",
        "outputId": "26eba8ce-25fc-4533-875e-49c0a96771ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOrV8htu5IZy",
        "outputId": "1356d5ff-26cb-4d81-851d-21ea59deb0ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Core Bottleneck Resnet from Lucidrains\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "def pair(x):\n",
        "    return (x, x) if not isinstance(x, tuple) else x\n",
        "\n",
        "def expand_dim(t, dim, k):\n",
        "    t = t.unsqueeze(dim = dim)\n",
        "    expand_shape = [-1] * len(t.shape)\n",
        "    expand_shape[dim] = k\n",
        "    return t.expand(*expand_shape)\n",
        "\n",
        "def rel_to_abs(x):\n",
        "    b, h, l, _, device, dtype = *x.shape, x.device, x.dtype\n",
        "    dd = {'device': device, 'dtype': dtype}\n",
        "    col_pad = torch.zeros((b, h, l, 1), **dd)\n",
        "    x = torch.cat((x, col_pad), dim = 3)\n",
        "    flat_x = rearrange(x, 'b h l c -> b h (l c)')\n",
        "    flat_pad = torch.zeros((b, h, l - 1), **dd)\n",
        "    flat_x_padded = torch.cat((flat_x, flat_pad), dim = 2)\n",
        "    final_x = flat_x_padded.reshape(b, h, l + 1, 2 * l - 1)\n",
        "    final_x = final_x[:, :, :l, (l-1):]\n",
        "    return final_x\n",
        "\n",
        "def relative_logits_1d(q, rel_k):\n",
        "    b, heads, h, w, dim = q.shape\n",
        "    logits = einsum('b h x y d, r d -> b h x y r', q, rel_k)\n",
        "    logits = rearrange(logits, 'b h x y r -> b (h x) y r')\n",
        "    logits = rel_to_abs(logits)\n",
        "    logits = logits.reshape(b, heads, h, w, w)\n",
        "    logits = expand_dim(logits, dim = 3, k = h)\n",
        "    return logits\n",
        "\n",
        "# positional embeddings\n",
        "\n",
        "class AbsPosEmb(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        fmap_size,\n",
        "        dim_head\n",
        "    ):\n",
        "        super().__init__()\n",
        "        height, width = pair(fmap_size)\n",
        "        scale = dim_head ** -0.5\n",
        "        self.height = nn.Parameter(torch.randn(height, dim_head) * scale)\n",
        "        self.width = nn.Parameter(torch.randn(width, dim_head) * scale)\n",
        "\n",
        "    def forward(self, q):\n",
        "        emb = rearrange(self.height, 'h d -> h () d') + rearrange(self.width, 'w d -> () w d')\n",
        "        emb = rearrange(emb, ' h w d -> (h w) d')\n",
        "        logits = einsum('b h i d, j d -> b h i j', q, emb)\n",
        "        return logits\n",
        "\n",
        "class RelPosEmb(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        fmap_size,\n",
        "        dim_head\n",
        "    ):\n",
        "        super().__init__()\n",
        "        height, width = pair(fmap_size)\n",
        "        scale = dim_head ** -0.5\n",
        "        self.fmap_size = fmap_size\n",
        "        self.rel_height = nn.Parameter(torch.randn(height * 2 - 1, dim_head) * scale)\n",
        "        self.rel_width = nn.Parameter(torch.randn(width * 2 - 1, dim_head) * scale)\n",
        "\n",
        "    def forward(self, q):\n",
        "        h, w = self.fmap_size\n",
        "\n",
        "        q = rearrange(q, 'b h (x y) d -> b h x y d', x = h, y = w)\n",
        "        rel_logits_w = relative_logits_1d(q, self.rel_width)\n",
        "        rel_logits_w = rearrange(rel_logits_w, 'b h x i y j-> b h (x y) (i j)')\n",
        "\n",
        "        q = rearrange(q, 'b h x y d -> b h y x d')\n",
        "        rel_logits_h = relative_logits_1d(q, self.rel_height)\n",
        "        rel_logits_h = rearrange(rel_logits_h, 'b h x i y j -> b h (y x) (j i)')\n",
        "        return rel_logits_w + rel_logits_h\n",
        "\n",
        "# classes\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        fmap_size,\n",
        "        heads = 4,\n",
        "        dim_head = 128,\n",
        "        rel_pos_emb = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "        inner_dim = heads * dim_head\n",
        "\n",
        "        self.to_qkv = nn.Conv2d(dim, inner_dim * 3, 1, bias = False)\n",
        "\n",
        "        rel_pos_class = AbsPosEmb if not rel_pos_emb else RelPosEmb\n",
        "        self.pos_emb = rel_pos_class(fmap_size, dim_head)\n",
        "\n",
        "    def forward(self, fmap):\n",
        "        heads, b, c, h, w = self.heads, *fmap.shape\n",
        "\n",
        "        q, k, v = self.to_qkv(fmap).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h d) x y -> b h (x y) d', h = heads), (q, k, v))\n",
        "\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = einsum('b h i d, b h j d -> b h i j', q, k)\n",
        "        sim = sim + self.pos_emb(q)\n",
        "\n",
        "        attn = sim.softmax(dim = -1)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h (x y) d -> b (h d) x y', x = h, y = w)\n",
        "        return out\n",
        "\n",
        "class BottleBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        fmap_size,\n",
        "        dim_out,\n",
        "        proj_factor,\n",
        "        downsample,\n",
        "        heads = 4,\n",
        "        dim_head = 128,\n",
        "        rel_pos_emb = False,\n",
        "        activation = nn.ReLU()\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # shortcut\n",
        "\n",
        "        if dim != dim_out or downsample:\n",
        "            kernel_size, stride, padding = (3, 2, 1) if downsample else (1, 1, 0)\n",
        "\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(dim, dim_out, kernel_size, stride = stride, padding = padding, bias = False),\n",
        "                nn.BatchNorm2d(dim_out),\n",
        "                activation\n",
        "            ).to('cuda:0')\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "        # contraction and expansion\n",
        "\n",
        "        attn_dim_in = dim_out // proj_factor\n",
        "        attn_dim_out = heads * dim_head\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(dim, attn_dim_in, 1, bias = False),\n",
        "            nn.BatchNorm2d(attn_dim_in),\n",
        "            activation,\n",
        "            Attention(\n",
        "                dim = attn_dim_in,\n",
        "                fmap_size = fmap_size,\n",
        "                heads = heads,\n",
        "                dim_head = dim_head,\n",
        "                rel_pos_emb = rel_pos_emb\n",
        "            ),\n",
        "            nn.AvgPool2d((2, 2)) if downsample else nn.Identity(),\n",
        "            nn.BatchNorm2d(attn_dim_out),\n",
        "            activation,\n",
        "            nn.Conv2d(attn_dim_out, dim_out, 1, bias = False),\n",
        "            nn.BatchNorm2d(dim_out)\n",
        "        ).to('cuda:0')\n",
        "\n",
        "        # init last batch norm gamma to zero\n",
        "\n",
        "        nn.init.zeros_(self.net[-1].weight)\n",
        "\n",
        "        # final activation\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = self.shortcut(x)\n",
        "        x = self.net(x)\n",
        "        x = x + shortcut\n",
        "        return self.activation(x)\n",
        "\n",
        "# main bottle stack\n",
        "\n",
        "class BottleStack(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        fmap_size,\n",
        "        dim_out = 2048,\n",
        "        proj_factor = 4,\n",
        "        num_layers = 3,\n",
        "        heads = 4,\n",
        "        dim_head = 128,\n",
        "        downsample = True,\n",
        "        rel_pos_emb = False,\n",
        "        activation = nn.ReLU()\n",
        "    ):\n",
        "        super().__init__()\n",
        "        fmap_size = pair(fmap_size)\n",
        "\n",
        "        self.dim = dim\n",
        "        self.fmap_size = fmap_size\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            is_first = i == 0\n",
        "            dim = (dim if is_first else dim_out)\n",
        "            layer_downsample = is_first and downsample\n",
        "\n",
        "            fmap_divisor = (2 if downsample and not is_first else 1)\n",
        "            layer_fmap_size = tuple(map(lambda t: t // fmap_divisor, fmap_size))\n",
        "\n",
        "            layers.append(BottleBlock(\n",
        "                dim = dim,\n",
        "                fmap_size = layer_fmap_size,\n",
        "                dim_out = dim_out,\n",
        "                proj_factor = proj_factor,\n",
        "                heads = heads,\n",
        "                dim_head = dim_head,\n",
        "                downsample = layer_downsample,\n",
        "                rel_pos_emb = rel_pos_emb,\n",
        "                activation = activation\n",
        "            ))\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, c, h, w = x.shape\n",
        "        assert c == self.dim, f'channels of feature map {c} must match channels given at init {self.dim}'\n",
        "        assert h == self.fmap_size[0] and w == self.fmap_size[1], f'height and width ({h} {w}) of feature map must match the fmap_size given at init {self.fmap_size}'\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "_QSJH8wE4lm6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchvision.models import resnet50\n",
        "layer = BottleStack(\n",
        "    dim = 256,\n",
        "    fmap_size = 56,        \n",
        "    dim_out = 2048,\n",
        "    proj_factor = 4,\n",
        "    downsample = True,\n",
        "    heads = 4,\n",
        "    dim_head = 128,\n",
        "    rel_pos_emb = True,\n",
        "    activation = nn.ReLU()\n",
        ")\n",
        "\n",
        "resnet = resnet50()\n",
        "\n",
        "backbone = list(resnet.children())\n",
        "\n",
        "model = nn.Sequential(\n",
        "    *backbone[:5],\n",
        "    layer,\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(1),\n",
        "    nn.Linear(2048, 1000)\n",
        ").to('cuda:0')\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "RUd9soLK57DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Parallelism communication over GPU-GPU\n",
        "\n",
        "from torchvision.models.resnet import ResNet, Bottleneck\n",
        "import torchvision.models as models\n",
        "\n",
        "num_batches = 3\n",
        "batch_size = 120\n",
        "image_w = 128\n",
        "image_h = 128\n",
        "num_classes = 1000\n",
        "\n",
        "#Exploit Simd MP\n",
        "class ModelParallelResNet50(ResNet):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(ModelParallelResNet50, self).__init__(\n",
        "            Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)\n",
        "\n",
        "        self.seq1 = nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.bn1,\n",
        "            self.relu,\n",
        "            self.maxpool,\n",
        "\n",
        "            self.layer1,\n",
        "            self.layer2\n",
        "        ).to('cuda:0')\n",
        "\n",
        "        self.seq2 = nn.Sequential(\n",
        "            self.layer3,\n",
        "            self.layer4,\n",
        "            self.avgpool,\n",
        "        ).to('cuda:0')\n",
        "        #can be .to('cuda:i+1')\n",
        "\n",
        "        self.fc.to('cuda:0')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.seq2(self.seq1(x).to('cuda:0'))\n",
        "        #can be .to('cuda:i+1')\n",
        "        return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "\n",
        "\n",
        "def train(model):\n",
        "    model.train(True)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "    one_hot_indices = torch.LongTensor(batch_size).random_(0, num_classes).view(batch_size, 1)\n",
        "\n",
        "    for _ in range(num_batches):\n",
        "        # generate random inputs and labels\n",
        "        inputs = torch.randn(batch_size, 3, image_w, image_h)\n",
        "        labels = torch.zeros(batch_size, num_classes).scatter_(1, one_hot_indices, 1)\n",
        "\n",
        "        # run forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.to('cuda:0'))\n",
        "\n",
        "        # run backward pass\n",
        "        labels = labels.to(outputs.device)\n",
        "        loss_fn(outputs, labels).backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "L6hRHUHe7-8F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import timeit\n",
        "import numpy as np\n",
        "num_repeat = 10\n",
        "\n",
        "stmt = \"train(model)\"\n",
        "\n",
        "setup = \"model = ModelParallelResNet50()\"\n",
        "mp_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
        "mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)\n",
        "\n",
        "setup = \"import torchvision.models as models;\" +\"model = models.resnet50(num_classes=num_classes).to('cuda:0')\"\n",
        "rn_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
        "rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)\n",
        "\n"
      ],
      "metadata": {
        "id": "iC8hIMbT8wyQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_run_times,rn_run_times"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_JjGqYw9Zsq",
        "outputId": "dd99d404-19d6-4711-b7ab-1c81340a9f12"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.1123716200002036,\n",
              "  1.1299691829999574,\n",
              "  1.074116351999919,\n",
              "  1.0834968939998362,\n",
              "  1.0637668520000716,\n",
              "  1.0647426460000133,\n",
              "  1.0603389860000334,\n",
              "  1.0544568430000254,\n",
              "  1.054915813999969,\n",
              "  1.0527757940001266],\n",
              " [1.0462304860000131,\n",
              "  1.0481395310000607,\n",
              "  1.0431353330000093,\n",
              "  1.040988293000055,\n",
              "  1.0490160489998743,\n",
              "  1.0621146959999805,\n",
              "  1.0407168409999485,\n",
              "  1.042717426000081,\n",
              "  1.0377378399998634,\n",
              "  1.0380829649998304])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(means, stds, labels, fig_name):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.bar(np.arange(len(means)), means, yerr=stds,\n",
        "           align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)\n",
        "    ax.set_ylabel('ResNet50 Execution Time (Second)')\n",
        "    ax.set_xticks(np.arange(len(means)))\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.yaxis.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig(fig_name)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "plot([mp_mean, rn_mean],\n",
        "     [mp_std, rn_std],\n",
        "     ['Model Parallel', 'Single GPU'],\n",
        "     'mp_vs_rn.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "ws8rLVHJ9ht_",
        "outputId": "320d1617-b348-4f0d-bb0c-7412c4b2829b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mp_mean,rn_mean)\n",
        "overhead_comms= abs(mp_mean/rn_mean)-1\n",
        "print(f\"{overhead_comms}% time wasted in comms.This will be more for multi tile GPUs \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AXdL9d1-MhW",
        "outputId": "e164983e-38e5-4193-955a-2575448c7d43"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0750950984000156 1.0448879459999716\n",
            "0.028909465857734018% time wasted in comms.This will be more for multi tile GPUs \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying distributed data/model parallelism\n",
        "\n",
        "class DataModelParallelismResNet50(ModelParallelResNet50):\n",
        "    def __init__(self, split_size, *args, **kwargs):\n",
        "        super(DataModelParallelismResNet50, self).__init__(*args, **kwargs)\n",
        "        self.split_size = split_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        splits = iter(x.split(self.split_size, dim=0))\n",
        "        s_next = next(splits)\n",
        "        #can be cuda i+1\n",
        "        s_prev = self.seq1(s_next).to('cuda:0')\n",
        "        ret = []\n",
        "\n",
        "        #standard loop /dataloader for iterating on splits\n",
        "        for s_next in splits:\n",
        "            # A. s_prev runs on cuda:i+1\n",
        "            #load prev bytestream to sequential 2 on cuda i+1\n",
        "            s_prev = self.seq2(s_prev)\n",
        "            ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n",
        "\n",
        "            # B. s_next runs on cuda:i, which can run concurrently with A\n",
        "            s_prev = self.seq1(s_next).to('cuda:0')\n",
        "\n",
        "        s_prev = self.seq2(s_prev)\n",
        "        ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n",
        "\n",
        "        return torch.cat(ret)\n",
        "#shard into 120/5 splits \n",
        "setup = \"model = DataModelParallelismResNet50(5)\"\n",
        "stmt = \"train(model)\"\n",
        "dmp_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
        "dmp_mean, dmp_std = np.mean(dmp_run_times), np.std(dmp_run_times)\n",
        "dmp_mean,dmp_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn1HePqgAWAr",
        "outputId": "0522118c-88e8-444b-8974-5351dd12d490"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.87293254160013, 0.19101611091171994)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot([mp_mean, dmp_mean],\n",
        "     [mp_std, dmp_std],\n",
        "     [' Model Parallel', ' Data Model Parallel '],\n",
        "     'mp_vs_rn.png')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "2X3IhO9-DXgy",
        "outputId": "d1a2e847-2f8e-4618-b3a5-6b195ae9f29e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAanElEQVR4nO3de5glVXnv8e9PQEFAUIeMZkRH5WKiAdQ+CtGYRsWox8hRiYJXiMfxGEHFu8YIcownxignBm8oKqjHGyYGFWOIocUYUGeQO4ocBbl5AYEBBHTkzR9VDdu2p3fN9NT07t7fz/PUs2utWlX19jy75t1VtWpVqgpJkkbNnRY6AEmSZmOCkiSNJBOUJGkkmaAkSSPJBCVJGklbLnQAG2rZsmW1cuXKhQ5DkrSJrFmz5uqq2mlm/aJLUCtXrmT16tULHYYkaRNJculs9V7ikySNJBOUJGkkmaAkSSPJBCVJGkkmKEnSSDJBSZJGkglKkjSSTFCSpJFkgpIkjSQTlCRpJJmgJGk2Rx4Jyaabjjxyof+iRSeL7ZXvExMT5Vh8kkbC5GTzOTW1kFEseknWVNXEzPrezqCSbJ3kW0nOTnJ+krfM0uYuST6d5OIk30yysq94JEmLS5+X+G4FHltVewJ7AU9MsveMNi8Erq2qXYCjgbf3GI8kaRHpLUFV48a2uFU7zbyeuD9wfDt/IvC4JOkrJknS4tHr+6CSbAGsAXYB3lNV35zRZAVwGUBVrUtyPXBP4OoZ21kFrAJYvnw5U17vlTQC9rruOgDO8v+kXvSaoKrq18BeSXYE/inJQ6rqvI3YzrHAsdB0kpicvjEpSQtpxx0B8P+kfmyWbuZVdR1wKvDEGYuuAHYGSLIlsANwzeaISZI02vrsxbdTe+ZEkm2A/YDvzmh2EvCCdv4A4N9rsfV7lyT1os9LfPcGjm/vQ90J+ExVfTHJUcDqqjoJOA74WJKLgZ8DB/YYjyRpEektQVXVOcBDZ6l/88D8LcCf9RWDJGnxcqgjSdJIMkFJkkaSCUqSNJJMUJKkkdTrg7qSlr6jT7looUNYMAdcezMAJ47xv8Hh++3W27Y9g5IkjSQTlCRpJJmgJEkjyQQlSRpJJihJ0kgyQUmSRpIJSpI0kkxQkqSRZIKSJI0kE5QkaSSZoCRJI6nzWHxJ7g78LnAzcElV3dZbVJKksTdngkqyA/BS4CDgzsDPgK2B5UnOAN5bVaf2HqUkaewMO4M6ETgB+KOqum5wQZKHA89L8oCqOq6vACVJ42nOBFVV+82xbA2wZpNHJEkjYO8T/oF9Pn5Mp7aHP2H3oW1Of+6hnPH8w+Yb1lgZdonvYXMtr6ozN204kjQaznj+YSaUBTbsEt8728+tgQngbCDAHsBqYJ/+QpMkjbM5u5lX1b5VtS9wFfCwqpqoqocDDwWu2BwBSpLGU9fnoHavqnOnC1V1HvB7/YQkSVL356DOSfIh4ONt+TnAOf2EJElS9wR1CPAS4OVt+TTgfb1EJEkSHRNUVd0CHN1OkiT1rlOCSvIo4EjgfoPrVNUD+glLkjTuul7iOw44nObB3F/3F44kSY2uCer6qvpyr5FIkjSgazfzU5O8I8k+SR42Pc21QpKdk5ya5IIk5yd5+SxtJpNcn+SsdnrzRv0VkqQlp+sZ1CPbz4mBugIeO8c664BXVdWZSbYH1iQ5paoumNHu61X1lI5xSJLGRNdefPtu6Iar6iqaESioqhuSXAisAGYmKEmSfkvXXnw7AEcAj2mrvgYcVVXXd1x/Jc3wSN+cZfE+Sc4GrgReXVXnz7L+KmAVwPLly5mamuqyW0mbwYpbbl3oELSApqau7G3bqarhjZLPAecBx7dVzwP2rKqnd1h3O5qE9tdV9Y8zlt0NuK2qbkzyZODvq2rXubY3MTFRq1evHhqzpM3j6FMuWugQtIAO32+3eW8jyZqqmphZ37WTxAOr6oiq+kE7vQUY+gxUkq2AzwGfmJmcAKpqbVXd2M6fDGyVZFnHmCRJS1jXBHVzkkdPF9oHd2+ea4UkoXl+6sKqetd62tyrbUeSR7TxXNMxJknSEta1F99LgOPbe1EA1wIHD1nnUTSXAs9NclZb90bgvgBV9X7gAOAlSdbRJLwDq8s1R0nSkte1F99ZwJ7tPSOqam2Hdf6D5uWGc7U5Buj2TmVJ0ljpdIkvyduS7NjeM1qb5O5J3tp3cJKk8dX1HtSTquq66UJVXQs8uZ+QJEnqnqC2SHKX6UKSbYC7zNFekqR56dpJ4hPAV5N8pC0fwh3PREmStMl17STx9na0h8e3Vf+7qr7SX1iSpHHX9QwK4EJgXVX9W5K7Jtm+qm7oKzBJ0njr2ovvRcCJwAfaqhXA5/sKSpKkrp0kXkrz4O1agKr6PvA7fQUlSVLXBHVrVf1yupBkS5r3QUmS1IuuCeprSd4IbJNkP+CzwBf6C0uSNO66JqjXAz8DzgVeDJwMvKmvoCRJ6trN/Dbgg0mOBx4MXOGgrpKkPs15BpXk/Uke3M7vAJwFnAB8J8lBmyE+SdKYGnaJ748GXsF+CHBRVf0B8HDgtb1GJkkaa8MS1C8H5vejffapqn7cW0SSJDE8QV2X5ClJHkrzHNS/wO3dzLfpOzhJ0vga1knixcC7gXsBrxg4c3oc8KU+A5Mkjbc5E1RVXQQ8cZb6rwAOFitJ6s2wXnxvSnL3OZY/NslTNn1YkqRxN+wS37nAF5PcApxJ87Du1sCuwF7AvwFv6zVCSdJYGnaJ75+Bf06yK00niXvTDBj7cWBVVd3cf4iSpHHUdSSJ7wPf7zkWSZJu13UsPkmSNisTlCRpJJmgJEkjqesr33dL8tUk57XlPZL4ug1JUm+6nkF9EHgD8CuAqjoHOLCvoCRJ6pqg7lpV35pRt25TByNJ0rSuCerqJA8ECiDJAcBVvUUlSRp7nZ6DAl4KHAs8KMkVwA+B5/YWlSRp7HU6g6qqH1TV44GdgAdV1aOr6pK51kmyc5JTk1yQ5PwkL5+lTZK8O8nFSc5J8rCN+iskSUtOpzOoJDsCzwdWAlsmAaCqXjbHauuAV1XVmUm2B9YkOaWqLhho8ySacf12BR4JvK/9lCSNua6X+E4GzqAZPPa2LitU1VW096mq6oYkFwIrgMEEtT9wQlUVcEaSHZPcu11XkjTGuiaoravqlRu7kyQrgYcC35yxaAVw2UD58rbuNxJUklXAKoDly5czNTW1saFI2sRW3HLrQoegBTQ1dWVv2+6aoD6W5EXAF4Hbv41V9fNhKybZDvgczRt5125MkFV1LE0nDSYmJmpycnJjNiOpB0efctFCh6AF9MzJ3XrbdtcE9UvgHcBf0nY1bz8fMNdKSbaiSU6fqKp/nKXJFcDOA+X7tHWSpDHXNUG9Ctilqq7uuuE0PSmOAy6sqnetp9lJwKFJPkXTOeJ67z9JkqB7groY+MUGbvtRwPOAc5Oc1da9EbgvQFW9n6bzxZMHtn/IBu5DkrREdU1QNwFnJTmV37wHtd5u5lX1H0Dm2mjbe++lHWOQJI2Rrgnq8+0kSdJm0fWV78f3HYgkSYPmTFBJPlNVz0xyLnf03rtdVe3RW2SSpLE27Azq6PbzKX0HIknSoGEJ6j3Aw6rq0s0RjCRJ04aNZj5nLzxJkvoy7AxqRZJ3r2/hkNHMJUnaaMMS1M3Ams0RiCRJg4YlqGvsYi5JWgjD7kH9crNEIUnSDHMmqKrae3MFIknSoGFnUJIkLQgTlCRpJHUdLJYkWwDLB9epqh/1EZQkSZ0SVJLDgCOAnwC3tdUFOBafJKkXXc+gXg7sXlXX9BmMJEnTut6Dugy4vs9AJEka1PUM6gfAVJIv8Ztv1H1XL1FJksZe1wT1o3a6cztJktSrrm/UfQtAku3a8o19BiVJUqd7UEkekuQ7wPnA+UnWJHlwv6FJksZZ104SxwKvrKr7VdX9gFcBH+wvLEnSuOuaoLatqlOnC1U1BWzbS0SSJLEBvfiS/BXwsbb8XJqefZIk9aLrGdSfAzsB/9hOO7V1kiT1omsvvmsBX+8uSdps5kxQSf5vVb0iyRdoxt77DVX11N4ikySNtWFnUNP3nP6u70AkSRo0Z4KqqjXt7F5V9feDy5K8HPhaX4FJksZb104SL5il7uC5Vkjy4SQ/TXLeepZPJrk+yVnt9OaOsUiSxsCwe1AHAc8G7p/kpIFF2wM/H7LtjwLHACfM0ebrVfWUDnFKksbMsHtQ/wlcBSwD3jlQfwNwzlwrVtVpSVbOJzhJ0vgadg/qUuBSYJ+e9r9PkrOBK4FXV9X5Pe1HkrTIdH3l+w3c0c38zsBWwE1Vdbd57PtM4H5VdWOSJwOfB3Zdz/5XAasAli9fztTU1Dx2K2lTWnHLrcMbacmamrqyt213fVB3++n5JAH2B/aez46rau3A/MlJ3ptkWVVdPUvbY2kGrGViYqImJyfns2tJm9DRp1y00CFoAT1zcrfett21F9/tqvF54E/ms+Mk92qTHUke0cZyzXy2KUlaOrpe4nv6QPFOwARwy5B1PglMAsuSXA4cQXNpkKp6P3AA8JIk64CbgQOr6rdGq5Akjaeuo5n/6cD8OuASmst861VVBw1ZfgxNN3RJkn5L13tQh/QdiCRJg7q+8v34JDsOlO+e5MP9hSVJGnddO0nsUVXXTRfa1288tJ+QJEnqnqDulOTu04Uk96D7/StJkjZY1yTzTuD0JJ9ty38G/HU/IUmS1L2TxAlJVgOPbaueXlUX9BeWJGncbciDuvegGd7oGOBnSe7fU0ySJHXuxXcE8DrgDW3VVsDH+wpKkqSuZ1BPA54K3ARQVVfSvBNKkqRedE1Qv2yHISqAJNv2F5IkSd0T1GeSfADYMcmLgH8DPtRfWJKkcde1F9/fJdkPWAvsDry5qk7pNTJJ0ljrOpr5C6vqOOCUtrxFkiOq6i29RidJGltdL/E9LsnJSe6d5MHAGdhJQpLUo66X+J6d5FnAuTQ9+Z5dVd/oNTJJ0ljr+hzUrsDLgc8BlwLPS3LXPgOTJI23rpf4vgD8VVW9GPhj4PvAt3uLSpI09roOFvuIqloL0D4P9c4kX+gvLEnSuJvzDCrJawGqam2SP5ux+OC+gpIkadglvgMH5t8wY9kTN3EskiTdbliCynrmZytLkrTJDEtQtZ752cqSJG0ywzpJ7JlkLc3Z0jbtPG15614jkySNtTkTVFVtsbkCkSRp0Ia8UVeSpM3GBCVJGkkmqKXkyCMh2XTTkUcu9F8kaYx1fd3GcmBFW7yiqn7SX0j9O/qUixY6hH486tnwr8+es8kBr34eACf+3ce6bXOJ/Vsdvt9uCx2CpI7mTFBJ9gLeD+wAXNFW3yfJdcBfVNWZPccnSRpTw86gPgq8uKq+OViZZG/gI8CePcWljbD3Cf/APh8/plPbw5+w+9A2pz/3UM54/mHzDUuSNsqwBLXtzOQEUFVnJNl2rhWTfBh4CvDTqnrILMsD/D3wZOAXwMGekc3PGc8/zIQiackY1kniy0m+lORZSf6wnZ6V5EvAvwxZ96PMPV7fk4Bd22kV8L6uQUuSlr5hD+q+LMmTgP0Z6CQBvKeqTh6y7mlJVs7RZH/ghPb1HWck2THJvavqqs7RS5KWrKG9+Krqy8CXe9j3CuCygfLlbd1vJagkq2jOsli+fDlTU1Pz2/Ett85rfS1eU1NXLnQIS47H03jr85ga1otvj6o6p53fCngd8AjgPOCtVfWL3iIbUFXHAscCTExM1OTk5Ly2t2S7mWuoZ07azXxT83gab30eU8PuQX10YP5vgF2AdwLb0HQ/n48rgJ0Hyvfhjq7skqQxN+wS3+A7nx4H/Leq+lWS04Cz57nvk4BDk3wKeCRwvfefJEnThiWoHZI8jeZM6y5V9SuAqqokc74PKskngUlgWZLLgSOArdr13w+cTNPF/GKabuaHzOPvkCQtMcMS1NeAp7bzZyRZXlU/SXIv4Oq5Vqyqg4YsL+ClnSOVJI2VYd3MDwFIcpequnWg/sdJntx3cJKk8dV1NPPTO9ZJkrRJDOtmfi+aZ5O2SfJQ7ug0cTfgrj3HJkkaY8PuQf0JcDBNF/B3DdSvBd7YU0ySJA29B3U8cHySZ1TV5zZTTJIkdb4H9Y0kxyX5MkCS30/ywh7jkiSNua4J6iPAV4DfbcsXAa/oJSJJkuieoJZV1WeA2wCqah3w696ikiSNva4J6qYk9wQKbn+j7vW9RSVJGntDX7fReiXN2HkPTPINYCfggN6ikiSNvU4JqqrOTPLHwO40z0J9b3pcPkmS+jDsQd3HrGfRPkmoqtN6iEmSpKFnUK+Zpa6APWje5bTFJo9IkiSGP6j7p4PlJI8C3gT8GDisx7gkSWOu0z2oJI8D/orm7OltVXVKr1FJksbesHtQ/x34S5ou5W+qqv/YLFFJksbesDOoLwCXA9cAr03y2sGFVfXUWdeSJGmehiWofTdLFJIkzTCsk8TXZtYluTuwc1Wd01tUkqSx12mooyRTSe6W5B7AmcAHk7xr2HqSJG2srmPx7VBVa4GnAydU1SOBx/cXliRp3HVNUFsmuTfwTOCLPcYjSRLQPUEdRfM+qP9fVd9O8gDg+/2FJUkad10Hi/0s8NmB8g+AZ/QVlCRJXTtJ7Jbkq0nOa8t7JHlTv6FJksZZ10t8HwTeAPwKoO1ifmBfQUmS1DVB3bWqvjWjbt2mDkaSpGldE9TVSR7IHa98PwC4qreoJEljr+sr318KHAs8KMkVwA+B5/QWlSRp7HXtxfcD4PFJtqU56/oFzT2oS3uMTZI0xua8xNcOb/SGJMck2Y8mMb0AuJjmod05JXliku8luTjJ62dZfnCSnyU5q53+58b+IZKkpWXYGdTHgGuB04EX0bwbKsDTquqsuVZMsgXwHmA/mld2fDvJSVV1wYymn66qQzcmeEnS0jUsQT2gqv4AIMmHaDpG3Leqbumw7UcAF7eXB0nyKWB/YGaCkiTptwxLUL+anqmqXye5vGNyAlgBXDZQvhx45CztnpHkMcBFwOFVddnMBklWAasAli9fztTUVMcQ1hPYLbfOa30tXlNTVy50CEuOx9N46/OYGpag9kyytp0PsE1bDlBVdbd57v8LwCer6tYkLwaOBx47s1FVHUvTi5CJiYmanJyc106PPuWiea2vxeuZk7stdAhLjsfTeOvzmBr2wsIt5rHtK4CdB8r3aesGt3/NQPFDwN/OY3+SpCWk64O6G+PbwK5J7p/kzjTd0k8abNC+wmPaU4ELe4xHkrSIdH1Qd4NV1bokh9K8pmML4MNVdX6So4DVVXUS8LIkT6UZNunnwMF9xSNJWlx6S1AAVXUycPKMujcPzL+BZhBaSZJ+Q5+X+CRJ2mgmKEnSSDJBSZJGkglKkjSSTFCSpJFkgpIkjSQTlCRpJJmgJEkjyQQlSRpJJihJ0kgyQUmSRpIJSpI0kkxQkqSRZIKSJI0kE5QkaSSZoCRJI8kEJUkaSSYoSdJIMkFJkkaSCUqSNJJMUJKkkWSCkiSNJBOUJGkkmaAkSSPJBCVJGkkmKEnSSDJBSZJGkglKkjSSTFCSpJFkgpIkjaReE1SSJyb5XpKLk7x+luV3SfLpdvk3k6zsMx5J0uLRW4JKsgXwHuBJwO8DByX5/RnNXghcW1W7AEcDb+8rHknS4tLnGdQjgIur6gdV9UvgU8D+M9rsDxzfzp8IPC5JeoxJkrRIbNnjtlcAlw2ULwceub42VbUuyfXAPYGrBxslWQWsaos3JvleLxGPj2XM+DceF69c6AC0FI3t8QSb7Ji632yVfSaoTaaqjgWOXeg4lookq6tqYqHjkJYCj6f+9HmJ7wpg54Hyfdq6Wdsk2RLYAbimx5gkSYtEnwnq28CuSe6f5M7AgcBJM9qcBLygnT8A+Peqqh5jkiQtEr1d4mvvKR0KfAXYAvhwVZ2f5ChgdVWdBBwHfCzJxcDPaZKY+uflUmnT8XjqSTxhkSSNIkeSkCSNJBOUJGkkmaA2sySXJPn6jLqzkpy3gduZSjJn19b1tWnrv5fk7CTfSLL7hux7jv1dkmRZO39jh/ZD22jpa78357bTBUnemmTrIevsmOQvNnJfHn8d2yw0E9TC2D7JdPf631ugGJ5TVXvSjOTxji4rtI8CSH3Yt6r+gGYEmgcAHxjSfkdggxNUy+NvkTBBLYzPAM9q5w8CPjm9IMnWST7S/pr8TpJ92/ptknwqyYVJ/gnYZmCdJyQ5PcmZST6bZLsNiOU0YJckK5N8vd3GmUn+sN32ZFt/EnBBW/f5JGuSnN+O8jGnJK9J8u0k5yR5ywbEpjFTVTcC/wv4H0nukWS7JF9tv5PnJpkeLu1vgAe2Zz/vmKPdbDz+FouqctqME3AJsDvwn235OzSD6Z7Xll9F0yUf4EHAj4CtaUYUma7fA1gHTNAMs3IasG277HXAm9v5KWBilhhurwdeA3wauCuwdVu3K82jAACTwE3A/QfWv0f7uQ1wHnDPgb9tWTt/Y/v5BJpuuKH5QfRF4DGDbZzGexr83gzUnUUzNNqWwN3aumXAxe13aeX0MdMum7Xdevbl8VeL4/gbu1PGEXENcG2SA4ELgV8MLHs08A8AVfXdJJcCuwGPAd7d1p+T5Jy2/d40B9g30oyze2fg9A4xfCLJzTRf6sOArYBjkuwF/Lrd57RvVdUPB8ovS/K0dn5nmgNqfSOAPKGdvtOWt2vbn9YhRo2vDHy+LcljgNtoxu9cvp72s7X78SxtPf4WyfFnglo4n6Z5HcnB89xOgFOq6qANXO85VbX69o0kRwI/Afak+aV1y0DbmwbaTQKPB/apql8kmaL5hTlXfP+nqobdU5AASLI9zRnSRcBzgJ2Ah1fVr5Jcwuzft67tpnn8LQLeg1o4/wT8Lc1IG4O+TnOwkWQ34L7A92h+8Ty7rX8IzWUGgDOARyXZpV22bbvehtoBuKqqbgOeRzP6x/raXdseHA+i+QU5l68Afz59XT7JiiS/sxHxaQy035P3Ap+vqmtpvm8/bZPOvtwx6vUNwPYDq66v3fp4/C0CJqgFUlU3VNXbq3lX1qD3AndKci7Nr7yDq+pW4H3AdkkuBI4C1rTb+RnNr8BPtpcdTqe5dr6h3gu8IMnZ7fo3rafdvwBbtnH8Dc0Bul5V9a/A/wNOb/+mE/nN/1gkgFPTdPX+Fs19nxe39Z8AJtrvzvOB7wJU1TU0l9XOS/KO9bVbH4+/xcGhjiRJI8kzKEnSSDJBSZJGkglKkjSSTFCSpJFkgpIkjSQTlCRpJJmgJEkj6b8AnlGA5fJrCbsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overhead_comms= abs(dmp_mean/mp_mean)-1\n",
        "print(f\"{overhead_comms}% time wasted in dmp comms since we have a single GPU.This will be less for multi tile GPUs \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT4Z2P3ZDsj7",
        "outputId": "8753ecf0-9927-4a4a-d4b0-3fd9e42d741d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6722589898100204% time wasted in dmp comms since we have a single GPU.This will be less for multi tile GPUs \n"
          ]
        }
      ]
    }
  ]
}